# Мастер-теорема

## Введение

Мастер-теорема (Master Theorem) является одним из наиболее важных инструментов для анализа асимптотической сложности
рекуррентных соотношений, которые возникают при анализе алгоритмов разделения и conquering (Divide and Conquer). Она
позволяет определить асимптотическое поведение времени выполнения алгоритма без необходимости подробного решения
рекуррентного уравнения. В этой статье мы докажем Master Theorem и рассмотрим ее практическое применение, а также
приведем примеры задач, иллюстрирующих ее использование.

## Практическое применение

Master Theorem широко используется в анализе алгоритмов, особенно в случаях, когда алгоритм разделяет задачу размера $n$
на $a$ подзадач, каждая из которых имеет размер $n/b$, и затем объединяет результаты этих подзадач. Примерами таких
алгоритмов являются сортировка слиянием (Merge Sort), быстрая сортировка (Quick Sort), алгоритм Strassen для умножения
матриц и многие другие.

## Определение

Master Theorem применима к рекуррентным соотношениям следующего вида:

$$
T(n) = aT\left(\frac{n}{b}\right) + f(n),
$$

где $a \geq 1$ и $b > 1$ — константы, а $f(n)$ — некоторая функция, характеризующая время, затрачиваемое на разделение
задачи и объединение результатов.

Master Theorem утверждает, что асимптотическое поведение $T(n)$ зависит от сравнения $f(n)$ с функцией $n^{\log_b a}$:

1. **Первый случай (f(n) много меньше n^{\log_b a}):** Если $f(n) = O(n^{\log_b a - \epsilon})$ для
   некоторого $\epsilon > 0$, то

$$
T(n) = \Theta(n^{\log_b a}).
$$

2. **Второй случай (f(n) примерно равно n^{\log_b a}):** Если $f(n) = \Theta(n^{\log_b a} \log^k n)$ для
   некоторого $k \geq 0$, то

$$
T(n) = \Theta(n^{\log_b a} \log^{k+1} n).
$$

3. **Третий случай (f(n) много больше n^{\log_b a}):** Если $f(n) = \Omega(n^{\log_b a + \epsilon})$ для
   некоторого $\epsilon > 0$, и если $a f\left(\frac{n}{b}\right) \leq c f(n)$ для некоторого $c < 1$ и для всех
   достаточно больших $n$, то

$$
T(n) = \Theta(f(n)).
$$

## Доказательство

Доказательство Master Theorem можно провести с помощью метода рекурсивного дерева (recursion tree method) или метода
замены (substitution method). Мы приведем доказательство для первого и третьего случаев, а второй случай можно доказать
аналогично.

### Первый случай

Пусть $f(n) = O(n^{\log_b a - \epsilon})$ для некоторого $\epsilon > 0$. Тогда рекурсивное дерево имеет
глубину $O(\log_b n)$, и каждая_level contributes $O(n^{\log_b a})$. Сумма всех_level'ов будет $O(n^{\log_b a})$, так
как $f(n)$ является незначительным по сравнению с $n^{\log_b a}$.

### Третий случай

Пусть $f(n) = \Omega(n^{\log_b a + \epsilon})$ для некоторого $\epsilon > 0$,
и $a f\left(\frac{n}{b}\right) \leq c f(n)$ для некоторого $c < 1$. В этом случае доминирующим термом является $f(n)$,
так как он растет быстрее, чем $n^{\log_b a}$. Поэтому, $T(n) = \Theta(f(n))$.

## Примеры

### Пример 1: T(n) = 2T(n/2) + n

Здесь $a = 2$, $b = 2$, $f(n) = n$, и $n^{\log_b a} = n^{\log_2 2} = n$. Таким образом, $f(n) = \Theta(n^{\log_b a})$,
что соответствует второму случаю Master Theorem. Следовательно,

$$
T(n) = \Theta(n \log n).
$$

### Пример 2: T(n) = 4T(n/2) + n

Здесь $a = 4$, $b = 2$, $f(n) = n$, и $n^{\log_b a} = n^{\log_2 4} = n^2$. Так как $f(n) = O(n^{2 - \epsilon})$
для $\epsilon = 1$, это соответствует первому случаю Master Theorem. Следовательно,

$$
T(n) = \Theta(n^2).
$$

### Пример 3: T(n) = T(n/2) + n^2

Здесь $a = 1$, $b = 2$, $f(n) = n^2$, и $n^{\log_b a} = n^{\log_2 1} = n^0 = 1$. Так
как $f(n) = \Omega(n^{0 + \epsilon})$ для $\epsilon = 2$, и $a f(n/b) = f(n/2) = (n/2)^2 = n^2 / 4 \leq c n^2$
для $c = 1/4 < 1$, это соответствует третьему случаю Master Theorem. Следовательно,

$$
T(n) = \Theta(n^2).
$$

# Псевдографические иллюстрации деревьев рекурсии для трех случаев Мастер-теоремы

## Введение

Для более эффективного объяснения трех случаев Мастер-теоремы с помощью псевдографических рекурсивных деревьев мы
представим распределение затрат на каждом уровне рекурсии. Этот подход помогает понять, как накапливаются затраты и
приводят к общей асимптотической сложности.

## Случай 1: \( f(n) = O(n^{\log_b a - \epsilon}) \) для некоторого \( \epsilon > 0 \)

**Пример:** \( T(n) = 4T(n/2) + n \)

- **Параметры:** \( a = 4 \), \( b = 2 \), \( \log_b a = 2 \)
- **Функция затрат:** \( f(n) = n \), которая является \( O(n^{2 - 1}) = O(n) \)

**Псевдографическое дерево:**

```
Уровень 0: n
    Уровень 1: 4*(n/2) = 2n
        Уровень 2: 16*(n/4) = 4n
            ...
                Уровень k: \( 4^k \cdot \frac{n}{2^k} = 2^k n \)
```

**Объяснение:**

- Затраты геометрически уменьшаются на каждом уровне.
- Общие затраты доминируют листьями.
- **Асимптотическая сложность:** \( \Theta(n^{\log_b a}) = \Theta(n^2) \)

## Случай 2: \( f(n) = \Theta(n^{\log_b a} \log^k n) \) для некоторого \( k \geq 0 \)

**Пример:** \( T(n) = 2T(n/2) + n \)

- **Параметры:** \( a = 2 \), \( b = 2 \), \( \log_b a = 1 \)
- **Функция затрат:** \( f(n) = n \), которая является \( \Theta(n \log^0 n) \)

**Псевдографическое дерево:**

```
Уровень 0: n
    Уровень 1: 2*(n/2) = n
        Уровень 2: 4*(n/4) = n
            ...
                Уровень k: \( 2^k \cdot \frac{n}{2^k} = n \)
```

**Объяснение:**

- Затраты остаются неизменными на каждом уровне.
- Общие затраты включают логарифмический фактор из-за количества уровней.
- **Асимптотическая сложность:** \( \Theta(n^{\log_b a} \log^{k+1} n) = \Theta(n \log n) \)

## Случай 3: \( f(n) = \Omega(n^{\log_b a + \epsilon}) \) для некоторого \( \epsilon > 0 \), и выполняется условие регулярности

**Пример:** \( T(n) = T(n/2) + n^2 \)

- **Параметры:** \( a = 1 \), \( b = 2 \), \( \log_b a = 0 \)
- **Функция затрат:** \( f(n) = n^2 \), которая является \( \Omega(n^{0 + 2}) = \Omega(n^2) \)

**Псевдографическое дерево:**

```
Уровень 0: n^2
    Уровень 1: (n/2)^2 = n^2 / 4
        Уровень 2: (n/4)^2 = n^2 / 16
            ...
                Уровень k: \( \left(\frac{n}{2^k}\right)^2 = n^2 / 4^k \)
```

**Объяснение:**

- Затраты быстро уменьшаются на каждом уровне.
- Общие затраты доминируют корнем.
- **Асимптотическая сложность:** \( \Theta(f(n)) = \Theta(n^2) \)

## Заключение

Эти псевдографические рекурсивные деревья предоставляют визуальное представление того, как накапливаются затраты в
каждом случае Мастер-теоремы. Обследуя распределение затрат и доминирование на разных уровнях, мы можем четко видеть,
как образуется общая асимптотическая сложность для каждого сценария. Этот подход улучшает понимание, иллюстрируя
теоретические концепции в конкретной, визуальной форме.

## Литература

1. Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). *Introduction to Algorithms* (3rd ed.). MIT
   Press.
2. Dasgupta, S., Papadimitriou, C. H., & Vazirani, U. V. (2008). *Algorithms*. McGraw-Hill.
3. Knuth, D. E. (1997). *The Art of Computer Programming, Volume 1: Fundamental Algorithms* (3rd ed.). Addison-Wesley.

---

Этот материал предоставляет подробное изложение Master Theorem, ее доказательства и практических примеров, которые
помогут специалистам в области алгоритмов глубже понять и применять эту теорему в своей работе.