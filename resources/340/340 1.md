#  Task340. Брокеры сообщений (на примере **Apache Kafka**)

### Дано:
- Разрабатываемая система обрабатывает сущности **{{Author}}**, **{{News}}**, **{{Tag}}** и **{{Comment}}**, которые логически связаны отношениями (см. предыдущие задачи)
    - один-ко-многим (**{{Author}}** и **{{News}}**, **{{News}}** и **{{Comment}}**)
    - многие-ко-многим (**{{News}}**, **{{Tag}}**).
- Существует и работает REST-передача между модулями **publisher** и **discussion** сущности **{{Comment}}**

### Задание
Необходимо в ранее разработанном распределенном приложении реализовать транспорт между модулями **publisher** и **discussion**
для сущности **{{Comment}}** через топики Kafka.

Основой для выполнения задания является следующая диаграмма взаимодействия

![sequence-diagram](media/340.svg)


### Технические требования

- Используйте префикс **/api/v1.0/** для контроллеров REST и их методов,
- Используйте адрес и порт **localhost:24110** для самого приложения (это модуль **publisher**).
- Не отключайте REST **localhost:24130** для модуля **discussion**.
- Используйте обязательный префикс **tbl_** для таблиц(ы) в базе(ах) данных
- Используйте подключение по умолчанию к **Kafka** из [hub.docker.com](https://hub.docker.com/r/confluentinc/cp-kafka)
  - Пример запуска:
    ```
    docker network create kafkanet

    docker run -d --network=kafkanet --name=zookeeper -e \
    ZOOKEEPER_CLIENT_PORT=2181 -e ZOOKEEPER_TICK_TIME=2000 -p 2181:2181 \
    confluentinc/cp-zookeeper
    
    docker run -d --network=kafkanet --name=kafka -e \
    KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 -e \
    KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e \
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -p 9092:9092 \
    confluentinc/cp-kafka
    ```
### Рекомендации

#### **Подготовительные шаги:**
- Изучить документацию по Apache Kafka.
- Установить и настроить Apache Kafka локально, используя docker.
- Создать поле state в сущности **{{Comment}}** с тремя состояниями PENDING APPROVE DELCINE
- Создать топики **InTopic** и **OutTopic** для обмена сообщениями или автоматизировать создание топиков при их отсутствии (Spring это делает автоматически)

#### Интеграция Kafka с **publisher:**
- Создать Kafka Producer в модуле **publisher** для отправки сообщений в топик **InTopic**.
- Настроить отправку **{{Comment}}** так, чтобы в топике **InTopic** сообщения 
  принадлежащие одной **{{News}}** всегда оказывались в одной **partition** (независимо от числа **partition**).
- Создать Kafka Consumer **publisher** для чтения сообщений из **OutTopic**.

#### Интеграция Kafka с **discussion:**
- Создать Kafka Consumer в модуле **discussion** для чтения запросов из топика **InTopic**:
  - модуль должен обновлять статус после автоматической модерации на APPROVE или DELCINE
  - алгоритм модерации может быть любым, например на основе стоп-слов
- Создать Kafka Producer в модуле **discussion** для отправки ответов в топик **OutTopic**.

#### Тестирование и отладка:
- Протестировать передачу сообщений через Kafka.
- Проверить регрессионно работоспособность системы после интеграции Kafka.

#### Масштабирование и оптимизация:
- Оптимизировать настройки Kafka для повышения производительности.
- Рассмотреть возможность масштабирования Kafka для обеспечения отказоустойчивости.
- Определить минимальное число брокеров, партиций и RF для обеспечения отказоустойчивости кластера Kafka.

### Дополнительные шаги (по желанию)
1. Оптимизировать производительность модуля/микросервиса **publisher** (например, использовать кеширование)
2. Настроить тестирование через развертывание базы данных в **Testcontainers**
3. Настроить мониторинг и логирование (тут масса вариантов)
