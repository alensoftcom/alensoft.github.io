## 1.1 Introduction

#### [](https://kafka.apache.org/documentation/#intro_streaming)[Что такое потоковая трансляция событий?](https://kafka.apache.org/documentation/#intro_streaming)

Потоковая передача событий — это цифровой эквивалент центральной нервной системы человеческого тела. Это технологическая основа для «всегда на связи» мира, где бизнес все больше определяется и автоматизируется программным обеспечением, а пользователь программного обеспечения — еще больше программное обеспечение.

С технической точки зрения, потоковая передача событий — это практика сбора данных в реальном времени из источников событий, таких как базы данных, датчики, мобильные устройства, облачные сервисы и программные приложения, в виде потоков событий; надежное хранение этих потоков событий для последующего извлечения; манипулирование, обработка и реагирование на потоки событий в реальном времени, а также ретроспективно; и маршрутизация потоков событий в различные технологии назначения по мере необходимости. Таким образом, потоковая передача событий обеспечивает непрерывный поток и интерпретацию данных, чтобы нужная информация находилась в нужном месте и в нужное время.

#### [](https://kafka.apache.org/documentation/#intro_usage)[Для чего можно использовать потоковую передачу событий?](https://kafka.apache.org/documentation/#intro_usage)

Потоковая передача событий применяется в [самых разных случаях использования](https://kafka.apache.org/powered-by) во множестве отраслей и организаций. Вот несколько примеров:

- Для обработки платежей и финансовых транзакций в режиме реального времени, например, на фондовых биржах, в банках и страховых компаниях.
- Для отслеживания и мониторинга автомобилей, грузовиков, автопарков и грузов в режиме реального времени, например, в логистике и автомобильной промышленности.
- Для непрерывного сбора и анализа данных датчиков с устройств Интернета вещей или другого оборудования, например, на заводах и ветряных электростанциях.
- Для сбора и немедленного реагирования на взаимодействия и заказы клиентов, например, в розничной торговле, гостиничном и туристическом бизнесе, а также в мобильных приложениях.
- Наблюдение за пациентами, находящимися на стационарном лечении, и прогнозирование изменений в их состоянии для обеспечения своевременного лечения в экстренных случаях.
- Для подключения, хранения и предоставления доступа к данным, полученным различными подразделениями компании.
- Служить основой для платформ данных, архитектур, управляемых событиями, и микросервисов.

#### [](https://kafka.apache.org/documentation/#intro_platform)[Apache Kafka® — это платформа потоковой передачи событий. Что это значит?](https://kafka.apache.org/documentation/#intro_platform)

Kafka объединяет три ключевые возможности, позволяющие вам реализовать [все варианты использования](https://kafka.apache.org/powered-by) потоковой передачи событий с помощью единого проверенного решения:

1. К **publish** (написать) и **subscribe to** (чтение) потоков событий, включая непрерывный импорт/экспорт ваших данных из других систем.
2. К **store** потоки событий надежно и так долго, как вам нужно.
3. К **process** потоки событий по мере их возникновения или ретроспективно.

И вся эта функциональность предоставляется распределенным, высокомасштабируемым, эластичным, отказоустойчивым и безопасным образом. Kafka может быть развернута на аппаратном обеспечении bare metal, виртуальных машинах и контейнерах, а также локально и в облаке. Вы можете выбирать между самоуправлением вашими средами Kafka и использованием полностью управляемых услуг, предлагаемых различными поставщиками.

#### [](https://kafka.apache.org/documentation/#intro_nutshell)[Как вкратце работает Кафка?](https://kafka.apache.org/documentation/#intro_nutshell)

Kafka — это распределенная система, состоящая из **servers** и **clients** которые взаимодействуют через высокопроизводительный [сетевой протокол TCP](https://kafka.apache.org/protocol.html) . Его можно развернуть на аппаратном обеспечении без ОС, виртуальных машинах и контейнерах как в локальных, так и в облачных средах.

**Servers** : Kafka работает как кластер из одного или нескольких серверов, которые могут охватывать несколько центров обработки данных или облачных регионов. Некоторые из этих серверов образуют уровень хранения, называемый брокерами. Другие серверы запускают [Kafka Connect](https://kafka.apache.org/documentation/#connect) для непрерывного импорта и экспорта данных в виде потоков событий для интеграции Kafka с вашими существующими системами, такими как реляционные базы данных, а также другими кластерами Kafka. Чтобы вы могли реализовать критически важные сценарии использования, кластер Kafka является высокомасштабируемым и отказоустойчивым: если какой-либо из его серверов выйдет из строя, другие серверы возьмут на себя его работу, чтобы обеспечить непрерывную работу без потери данных.

**Clients** : Они позволяют вам писать распределенные приложения и микросервисы, которые считывают, записывают и обрабатывают потоки событий параллельно, в масштабе и отказоустойчивым образом даже в случае сетевых проблем или сбоев оборудования. Kafka поставляется с некоторыми такими клиентами, которые дополняются [десятками клиентов,](https://cwiki.apache.org/confluence/display/KAFKA/Clients) предоставляемых сообществом Kafka: клиенты доступны для Java и Scala, включая библиотеку [Kafka Streams](https://kafka.apache.org/documentation/streams/) более высокого уровня , для Go, Python, C/C++ и многих других языков программирования, а также REST API.

#### [](https://kafka.apache.org/documentation/#intro_concepts_and_terms)[Основные понятия и терминология](https://kafka.apache.org/documentation/#intro_concepts_and_terms)

**Событие** записывает факт, что «что-то произошло» в мире или в вашем бизнесе. В документации это также называется записью или сообщением. Когда вы читаете или записываете данные в Kafka, вы делаете это в форме событий. Концептуально событие имеет ключ, значение, временную метку и необязательные заголовки метаданных. Вот пример события:

- Ключ события: «Алиса»
- Значение события: «Сделал платеж в размере 200 долларов Бобу»
- Временная метка события: «25 июня 2020 г., 14:06»

**Producers** это те клиентские приложения, которые публикуют (записывают) события в Kafka, и **consumers** те, кто подписываются на (читают и обрабатывают) эти события. В Kafka производители и потребители полностью развязаны и не зависят друг от друга, что является ключевым элементом дизайна для достижения высокой масштабируемости, которой славится Kafka. Например, производителям никогда не нужно ждать потребителей. Kafka предоставляет различные [гарантии](https://kafka.apache.org/documentation/#semantics) , такие как возможность обрабатывать события только один раз.

Мероприятия организуются и надежно хранятся в **topics** . Очень упрощенно, тема похожа на папку в файловой системе, а события — это файлы в этой папке. Примером имени темы может быть «платежи». Темы в Kafka всегда являются многопроизводительными и многоподписными: у темы может быть ноль, один или много производителей, которые записывают в нее события, а также ноль, один или много потребителей, которые подписываются на эти события. События в теме можно читать так часто, как это необходимо — в отличие от традиционных систем обмена сообщениями, события не удаляются после потребления. Вместо этого вы определяете, как долго Kafka должна хранить ваши события с помощью настройки конфигурации для каждой темы, после чего старые события будут отбрасываться. Производительность Kafka фактически постоянна относительно размера данных, поэтому хранение данных в течение длительного времени вполне приемлемо.

Темы есть **partitioned** , что означает, что тема распределена по нескольким "корзинам", расположенным на разных брокерах Kafka. Такое распределенное размещение ваших данных очень важно для масштабируемости, поскольку оно позволяет клиентским приложениям как считывать, так и записывать данные с/на многих брокеров одновременно. Когда новое событие публикуется в теме, оно фактически добавляется к одному из разделов темы. События с одинаковым ключом события (например, идентификатор клиента или транспортного средства) записываются в один и тот же раздел, и Kafka [гарантирует](https://kafka.apache.org/documentation/#semantics) , что любой потребитель данного раздела темы всегда будет читать события этого раздела точно в том же порядке, в котором они были записаны.

![Тема-Хранение](http://localhost:24100/media/340-02.png)

Рисунок: Этот пример темы имеет четыре раздела P1–P4. Два разных клиента-производителя публикуют, независимо друг от друга, новые события в теме, записывая события по сети в разделы темы. События с одинаковым ключом (обозначенные их цветом на рисунке) записываются в один и тот же раздел. Обратите внимание, что оба производителя могут писать в один и тот же раздел, если это уместно.

Чтобы сделать ваши данные отказоустойчивыми и высокодоступными, каждую тему можно **replicated** , даже в географических регионах или центрах обработки данных, так что всегда есть несколько брокеров, у которых есть копия данных на случай, если что-то пойдет не так, вы захотите провести техническое обслуживание брокеров и т. д. Распространенная производственная настройка — это фактор репликации 3, т. е. всегда будет три копии ваших данных. Эта репликация выполняется на уровне разделов тем.

Этого руководства должно быть достаточно для введения. Раздел документации [«Дизайн»](https://kafka.apache.org/documentation/#design) подробно объясняет различные концепции Kafka, если вам интересно.

#### [](https://kafka.apache.org/documentation/#intro_apis)[API Кафки](https://kafka.apache.org/documentation/#intro_apis)

Помимо инструментов командной строки для задач управления и администрирования, Kafka имеет пять основных API для Java и Scala:

- API [администратора](https://kafka.apache.org/documentation.html#adminapi) для управления и проверки тем, брокеров и других объектов Kafka.
- API [-интерфейс Producer](https://kafka.apache.org/documentation.html#producerapi) для публикации (записи) потока событий в одну или несколько тем Kafka.
- API [потребителя](https://kafka.apache.org/documentation.html#consumerapi) для подписки (чтения) одной или нескольких тем и обработки потока событий, созданных для них.
- API [Kafka Streams](https://kafka.apache.org/documentation/streams) для реализации приложений потоковой обработки и микросервисов. Он предоставляет функции более высокого уровня для обработки потоков событий, включая преобразования, операции с сохранением состояния, такие как агрегации и объединения, оконную обработку, обработку на основе времени события и многое другое. Входные данные считываются из одной или нескольких тем для генерации выходных данных в одну или несколько тем, эффективно преобразуя входные потоки в выходные потоки.
- API [Kafka Connect](https://kafka.apache.org/documentation.html#connect) для создания и запуска повторно используемых коннекторов импорта/экспорта данных, которые потребляют (читают) или производят (записывают) потоки событий из внешних систем и приложений и во внешние системы, чтобы они могли интегрироваться с Kafka. Например, коннектор к реляционной базе данных, такой как PostgreSQL, может фиксировать каждое изменение в наборе таблиц. Однако на практике вам обычно не нужно реализовывать собственные коннекторы, поскольку сообщество Kafka уже предоставляет сотни готовых к использованию коннекторов.

#### [](https://kafka.apache.org/documentation/#intro_more)[Куда идти дальше](https://kafka.apache.org/documentation/#intro_more)

- Чтобы получить практический опыт работы с Kafka, следуйте [краткому руководству](https://kafka.apache.org/quickstart) .
- Чтобы понять Кафку более подробно, прочтите [Документацию](https://kafka.apache.org/documentation/) . У вас также есть выбор [книг и научных работ Кафки](https://kafka.apache.org/books-and-papers) .
- Просмотрите [примеры использования](https://kafka.apache.org/powered-by) , чтобы узнать, как другие пользователи нашего мирового сообщества извлекают пользу из Kafka.
- Присоединяйтесь к [местной группе встреч Kafka](https://kafka.apache.org/events) и [смотрите выступления на Kafka Summit](https://kafka-summit.org/past-events/) , главной конференции сообщества Kafka.

### [1.2 Use Cases](https://kafka.apache.org/documentation/#uses)

Вот описание нескольких популярных вариантов использования Apache Kafka®. Для обзора ряда этих областей в действии см. [этот пост в блоге](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying/) .

#### [Обмен сообщениями](https://kafka.apache.org/documentation/#uses_messaging)

Kafka хорошо работает в качестве замены более традиционному брокеру сообщений. Брокеры сообщений используются по разным причинам (для отделения обработки от производителей данных, для буферизации необработанных сообщений и т. д.). По сравнению с большинством систем обмена сообщениями Kafka имеет лучшую пропускную способность, встроенное разделение, репликацию и отказоустойчивость, что делает его хорошим решением для крупномасштабных приложений обработки сообщений.

![Обмен сообщениями](http://localhost:24100/media/340-03.png)

По нашему опыту, обмен сообщениями часто требует сравнительно низкой пропускной способности, но может потребовать небольшой сквозной задержки и часто зависит от надежных гарантий надежности, предоставляемых Kafka.

В этой области Kafka сопоставима с традиционными системами обмена сообщениями, такими как [ActiveMQ](https://activemq.apache.org/) или [RabbitMQ](https://www.rabbitmq.com/) .

#### [Отслеживание активности на сайте](https://kafka.apache.org/documentation/#uses_website)

Первоначальный вариант использования Kafka заключался в том, чтобы иметь возможность перестроить конвейер отслеживания активности пользователя в виде набора каналов публикации-подписки в реальном времени. Это означает, что активность сайта (просмотры страниц, поиски или другие действия, которые могут выполнять пользователи) публикуется в центральных темах с одной темой на тип активности. Эти каналы доступны для подписки для ряда вариантов использования, включая обработку в реальном времени, мониторинг в реальном времени и загрузку в Hadoop или автономные системы хранения данных для автономной обработки и отчетности.

Отслеживание активности часто осуществляется в очень больших объемах, поскольку для каждого просмотра страницы пользователем генерируется множество сообщений об активности.

#### [Метрики](https://kafka.apache.org/documentation/#uses_metrics)

Kafka часто используется для данных оперативного мониторинга. Это подразумевает агрегацию статистики из распределенных приложений для создания централизованных потоков оперативных данных.

#### [Агрегация журналов](https://kafka.apache.org/documentation/#uses_logs)

Многие используют Kafka в качестве замены решения для агрегации журналов. Агрегация журналов обычно собирает физические файлы журналов с серверов и помещает их в центральное место (возможно, файловый сервер или HDFS) для обработки. Kafka абстрагирует детали файлов и дает более чистую абстракцию данных журнала или событий в виде потока сообщений. Это позволяет выполнять обработку с меньшей задержкой и упрощает поддержку нескольких источников данных и распределенного потребления данных. По сравнению с системами, ориентированными на журналы, такими как Scribe или Flume, Kafka предлагает одинаково хорошую производительность, более высокие гарантии долговечности благодаря репликации и гораздо более низкую сквозную задержку.

#### [Потоковая обработка](https://kafka.apache.org/documentation/#uses_streamprocessing)

Многие пользователи Kafka обрабатывают данные в конвейерах обработки, состоящих из нескольких этапов, где необработанные входные данные потребляются из тем Kafka, а затем агрегируются, обогащаются или иным образом преобразуются в новые темы для дальнейшего потребления или последующей обработки. Например, конвейер обработки для рекомендации новостных статей может сканировать содержимое статьи из RSS-каналов и публиковать его в теме «статьи»; дальнейшая обработка может нормализовать или дедуплицировать это содержимое и публиковать очищенное содержимое статьи в новой теме; конечный этап обработки может попытаться рекомендовать это содержимое пользователям. Такие конвейеры обработки создают графики потоков данных в реальном времени на основе отдельных тем. Начиная с версии 0.10.0.0, в Apache Kafka доступна легкая, но мощная библиотека потоковой обработки под названием [Kafka Streams](https://kafka.apache.org/documentation/streams) для выполнения такой обработки данных, как описано выше. Помимо Kafka Streams, альтернативными инструментами потоковой обработки с открытым исходным кодом являются [Apache Storm](https://storm.apache.org/) и [Apache Samza](https://samza.apache.org/) .

#### [Поиск мероприятий](https://kafka.apache.org/documentation/#uses_eventsourcing)

[Источник событий](https://martinfowler.com/eaaDev/EventSourcing.html) — это стиль дизайна приложений, в котором изменения состояния регистрируются как упорядоченная по времени последовательность записей. Поддержка Kafka очень больших хранимых данных журнала делает его превосходным бэкэндом для приложения, созданного в этом стиле.

#### [Журнал фиксации](https://kafka.apache.org/documentation/#uses_commitlog)

Kafka может служить своего рода внешним журналом коммитов для распределенной системы. Журнал помогает реплицировать данные между узлами и действует как механизм повторной синхронизации для отказавших узлов для восстановления их данных. Функция [сжатия журналов](https://kafka.apache.org/documentation.html#compaction) в Kafka помогает поддерживать такое использование. В этом использовании Kafka похож на проект [Apache BookKeeper](https://bookkeeper.apache.org/) .